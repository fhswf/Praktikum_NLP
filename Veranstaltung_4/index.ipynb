{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.ki.fh-swf.de/jupyterhub/hub/user-redirect/git-pull?profile=nlp-environment&repo=https%3A%2F%2Fgithub.com%2Ffhswf%2FPraktikum_NLP.git&urlpath=lab%2Ftree%2FPraktikum_NLP.git%2FVeranstaltung_4%2Findex.ipynb&branch=main\" style=\"\"><img src=\"https://www.ki.fh-swf.de/cluster_badge.svg\" style=\"height: 32px\" alt=\"Open in FH Cluster\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Praktikum: NER mit der Transformer-Bibliothek\n",
    "\n",
    "In diesem Praktikum woll wir ein Named-Entity-Recognition-Modell für die Deutsche Sprache trainieren.\n",
    "Als Trainingsdatensatz verwenden wir *GermEval 2014*.\n",
    "\n",
    "Der eigentliche Code entspricht [Beispielcode](https://github.com/huggingface/transformers/blob/main/examples/pytorch/token-classification/run_ner.py), den Huggingface in seinem GitHub-Repository bereitstellt. Dieser ist im letzten Jahr deutlich einfacher geworden, da er beispielsweise direkt auf die Datasets-Bibliothek zurückgreift. \n",
    "\n",
    "Zunächst installieren wir die benötigten Bibliotheken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch==2.4.0 in /opt/conda/lib/python3.11/site-packages (2.4.0+cu121)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.11/site-packages (4.43.4)\n",
      "Collecting transformers\n",
      "  Using cached transformers-4.46.3-py3-none-any.whl.metadata (44 kB)\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.11/site-packages (3.0.1)\n",
      "Collecting datasets\n",
      "  Using cached datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: evaluate in /opt/conda/lib/python3.11/site-packages (0.4.3)\n",
      "Collecting seqeval\n",
      "  Using cached seqeval-1.2.2-py3-none-any.whl\n",
      "Collecting lightning-flash[text]\n",
      "  Using cached lightning_flash-0.8.2-py3-none-any.whl.metadata (27 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch==2.4.0) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.11/site-packages (from torch==2.4.0) (4.8.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch==2.4.0) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch==2.4.0) (3.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch==2.4.0) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch==2.4.0) (2023.9.2)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.4.0)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.4.0)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.4.0)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.4.0)\n",
      "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.4.0)\n",
      "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.4.0)\n",
      "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.4.0)\n",
      "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.4.0)\n",
      "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.4.0)\n",
      "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.4.0)\n",
      "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch==2.4.0) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /opt/conda/lib/python3.11/site-packages (from torch==2.4.0) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.0) (12.2.140)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from lightning-flash[text]) (23.2)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.11/site-packages (from lightning-flash[text]) (68.2.2)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from lightning-flash[text]) (1.24.4)\n",
      "Collecting torchmetrics<0.11.0,>0.7.0 (from lightning-flash[text])\n",
      "  Using cached torchmetrics-0.10.3-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pytorch-lightning<2.0.0,>1.8.0 (from lightning-flash[text])\n",
      "  Using cached pytorch_lightning-1.9.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting pyDeprecate>0.2.0 (from lightning-flash[text])\n",
      "  Using cached pyDeprecate-0.3.2-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas>1.1.0 in /opt/conda/lib/python3.11/site-packages (from lightning-flash[text]) (2.1.1)\n",
      "Collecting jsonargparse>=4.22.0 (from jsonargparse[signatures]>=4.22.0->lightning-flash[text])\n",
      "  Using cached jsonargparse-4.34.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: click>=7.1.2 in /opt/conda/lib/python3.11/site-packages (from lightning-flash[text]) (8.1.7)\n",
      "Requirement already satisfied: protobuf in /opt/conda/lib/python3.11/site-packages (from lightning-flash[text]) (4.24.3)\n",
      "Collecting lightning-utilities>=0.4.1 (from lightning-flash[text])\n",
      "  Downloading lightning_utilities-0.11.9-py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: regex in /opt/conda/lib/python3.11/site-packages (from lightning-flash[text]) (2024.9.11)\n",
      "Requirement already satisfied: sentencepiece>=0.1.95 in /opt/conda/lib/python3.11/site-packages (from lightning-flash[text]) (0.1.95)\n",
      "Collecting sentence-transformers (from lightning-flash[text])\n",
      "  Using cached sentence_transformers-3.3.1-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: ftfy in /opt/conda/lib/python3.11/site-packages (from lightning-flash[text]) (6.3.0)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.11/site-packages (from lightning-flash[text]) (0.19.0+cu121)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.26.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.21,>=0.20 (from transformers)\n",
      "  Downloading tokenizers-0.20.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.11/site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.11/site-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.11/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/conda/lib/python3.11/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.11/site-packages (from datasets) (3.10.5)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/lib/python3.11/site-packages (from seqeval) (1.3.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (1.11.1)\n",
      "Collecting docstring-parser>=0.15 (from jsonargparse[signatures]>=4.22.0->lightning-flash[text])\n",
      "  Using cached docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting typeshed-client>=2.1.0 (from jsonargparse[signatures]>=4.22.0->lightning-flash[text])\n",
      "  Using cached typeshed_client-2.7.0-py3-none-any.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas>1.1.0->lightning-flash[text]) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas>1.1.0->lightning-flash[text]) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.11/site-packages (from pandas>1.1.0->lightning-flash[text]) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2023.7.22)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn>=0.21.3->seqeval) (1.11.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from scikit-learn>=0.21.3->seqeval) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn>=0.21.3->seqeval) (3.2.0)\n",
      "Requirement already satisfied: nltk>=3.6 in /opt/conda/lib/python3.11/site-packages (from torchmetrics[text]>0.5.0; extra == \"text\"->lightning-flash[text]) (3.9.1)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.11/site-packages (from ftfy->lightning-flash[text]) (0.2.8)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch==2.4.0) (2.1.3)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.11/site-packages (from sentence-transformers->lightning-flash[text]) (10.1.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.11/site-packages (from sympy->torch==2.4.0) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas>1.1.0->lightning-flash[text]) (1.16.0)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /opt/conda/lib/python3.11/site-packages (from typeshed-client>=2.1.0->jsonargparse[signatures]>=4.22.0->lightning-flash[text]) (6.1.0)\n",
      "Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
      "Using cached transformers-4.46.3-py3-none-any.whl (10.0 MB)\n",
      "Using cached datasets-3.1.0-py3-none-any.whl (480 kB)\n",
      "Using cached jsonargparse-4.34.0-py3-none-any.whl (210 kB)\n",
      "Downloading lightning_utilities-0.11.9-py3-none-any.whl (28 kB)\n",
      "Using cached pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n",
      "Using cached pytorch_lightning-1.9.5-py3-none-any.whl (829 kB)\n",
      "Downloading tokenizers-0.20.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached torchmetrics-0.10.3-py3-none-any.whl (529 kB)\n",
      "Using cached lightning_flash-0.8.2-py3-none-any.whl (1.2 MB)\n",
      "Using cached sentence_transformers-3.3.1-py3-none-any.whl (268 kB)\n",
      "Using cached docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
      "Using cached typeshed_client-2.7.0-py3-none-any.whl (624 kB)\n",
      "Installing collected packages: typeshed-client, pyDeprecate, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, jsonargparse, docstring-parser, nvidia-cusolver-cu12, nvidia-cudnn-cu12, tokenizers, seqeval, transformers, torchmetrics, datasets, sentence-transformers, pytorch-lightning, lightning-flash\n",
      "  Attempting uninstall: nvidia-nccl-cu12\n",
      "    Found existing installation: nvidia-nccl-cu12 2.16.5\n",
      "    Uninstalling nvidia-nccl-cu12-2.16.5:\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.16.5\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.1.2.141\n",
      "    Uninstalling nvidia-cusparse-cu12-12.1.2.141:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.1.2.141\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.3.141\n",
      "    Uninstalling nvidia-curand-cu12-10.3.3.141:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.3.141\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.0.8.103\n",
      "    Uninstalling nvidia-cufft-cu12-11.0.8.103:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.0.8.103\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.2.140\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.2.140:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.2.140\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.2.140\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.2.140:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.2.140\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.2.142\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.2.142:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.2.142\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.2.5.6\n",
      "    Uninstalling nvidia-cublas-cu12-12.2.5.6:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.2.5.6\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.5.2.141\n",
      "    Uninstalling nvidia-cusolver-cu12-11.5.2.141:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.5.2.141\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 8.9.4.25\n",
      "    Uninstalling nvidia-cudnn-cu12-8.9.4.25:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-8.9.4.25\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.19.1\n",
      "    Uninstalling tokenizers-0.19.1:\n",
      "      Successfully uninstalled tokenizers-0.19.1\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.43.4\n",
      "    Uninstalling transformers-4.43.4:\n",
      "      Successfully uninstalled transformers-4.43.4\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 3.0.1\n",
      "    Uninstalling datasets-3.0.1:\n",
      "      Successfully uninstalled datasets-3.0.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "adapters 1.0.0 requires transformers~=4.43.3, but you have transformers 4.46.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed datasets-3.1.0 docstring-parser-0.16 jsonargparse-4.34.0 lightning-flash-0.8.2 lightning-utilities-0.11.9 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 pyDeprecate-0.3.2 pytorch-lightning-1.9.5 sentence-transformers-3.3.1 seqeval-1.2.2 tokenizers-0.20.4 torchmetrics-0.10.3 transformers-4.46.3 typeshed-client-2.7.0\n"
     ]
    }
   ],
   "source": [
    "!pip install 'lightning-flash[text]' torch==2.4.0 transformers datasets evaluate seqeval --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and clean data for GermEval 2014 NER task\n",
    "\n",
    "The following lines download the dataset via the Huggingface `datasets` library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '0',\n",
       " 'source': 'n-tv.de vom 26.02.2005 [2005-02-26] ',\n",
       " 'tokens': ['Schartau',\n",
       "  'sagte',\n",
       "  'dem',\n",
       "  '\"',\n",
       "  'Tagesspiegel',\n",
       "  '\"',\n",
       "  'vom',\n",
       "  'Freitag',\n",
       "  ',',\n",
       "  'Fischer',\n",
       "  'sei',\n",
       "  '\"',\n",
       "  'in',\n",
       "  'einer',\n",
       "  'Weise',\n",
       "  'aufgetreten',\n",
       "  ',',\n",
       "  'die',\n",
       "  'alles',\n",
       "  'andere',\n",
       "  'als',\n",
       "  'überzeugend',\n",
       "  'war',\n",
       "  '\"',\n",
       "  '.'],\n",
       " 'ner_tags': [19,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  7,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  19,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'nested_ner_tags': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"germeval_14\")\n",
    "\n",
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model\n",
    "\n",
    "The following code is taken from the [transformer NER example script](https://github.com/huggingface/transformers/blob/main/examples/pytorch/token-classification/run_ner.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-27 09:10:37.877955: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-27 09:10:37.878054: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-27 09:10:37.879700: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-27 09:10:37.887405: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-27 09:10:38.803802: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "import sys\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional\n",
    "\n",
    "import datasets\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from datasets import ClassLabel, load_dataset\n",
    "\n",
    "import transformers\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModelForTokenClassification,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorForTokenClassification,\n",
    "    HfArgumentParser,\n",
    "    PretrainedConfig,\n",
    "    PreTrainedTokenizerFast,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    set_seed,\n",
    ")\n",
    "from transformers.trainer_utils import get_last_checkpoint\n",
    "from transformers.utils import check_min_version, send_example_telemetry\n",
    "from transformers.utils.versions import require_version\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Klassen zur Parametrisierung des Trainings\n",
    "\n",
    "Die folgenden Klassen parametrisieren das Training. Zunächst die Klasse zur Auswahl des Modells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ModelArguments:\n",
    "    \"\"\"\n",
    "    Arguments pertaining to which model/config/tokenizer we are going to fine-tune from.\n",
    "    \"\"\"\n",
    "\n",
    "    model_name_or_path: str = field(\n",
    "        metadata={\"help\": \"Path to pretrained model or model identifier from huggingface.co/models\"}\n",
    "    )\n",
    "    config_name: Optional[str] = field(\n",
    "        default=None, metadata={\"help\": \"Pretrained config name or path if not the same as model_name\"}\n",
    "    )\n",
    "    tokenizer_name: Optional[str] = field(\n",
    "        default=None, metadata={\"help\": \"Pretrained tokenizer name or path if not the same as model_name\"}\n",
    "    )\n",
    "    cache_dir: Optional[str] = field(\n",
    "        default=None,\n",
    "        metadata={\"help\": \"Where do you want to store the pretrained models downloaded from huggingface.co\"},\n",
    "    )\n",
    "    model_revision: str = field(\n",
    "        default=\"main\",\n",
    "        metadata={\"help\": \"The specific model version to use (can be a branch name, tag name or commit id).\"},\n",
    "    )\n",
    "    use_auth_token: bool = field(\n",
    "        default=False,\n",
    "        metadata={\n",
    "            \"help\": (\n",
    "                \"Will use the token generated when running `huggingface-cli login` (necessary to use this script \"\n",
    "                \"with private models).\"\n",
    "            )\n",
    "        },\n",
    "    )\n",
    "    ignore_mismatched_sizes: bool = field(\n",
    "        default=False,\n",
    "        metadata={\"help\": \"Will enable to load a pretrained model whose head dimensions are different.\"},\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DataTrainingArguments:\n",
    "    \"\"\"\n",
    "    Arguments pertaining to what data we are going to input our model for training and eval.\n",
    "    \"\"\"\n",
    "\n",
    "    task_name: Optional[str] = field(default=\"ner\", metadata={\"help\": \"The name of the task (ner, pos...).\"})\n",
    "    dataset_name: Optional[str] = field(\n",
    "        default=None, metadata={\"help\": \"The name of the dataset to use (via the datasets library).\"}\n",
    "    )\n",
    "    dataset_config_name: Optional[str] = field(\n",
    "        default=None, metadata={\"help\": \"The configuration name of the dataset to use (via the datasets library).\"}\n",
    "    )\n",
    "    train_file: Optional[str] = field(\n",
    "        default=None, metadata={\"help\": \"The input training data file (a csv or JSON file).\"}\n",
    "    )\n",
    "    validation_file: Optional[str] = field(\n",
    "        default=None,\n",
    "        metadata={\"help\": \"An optional input evaluation data file to evaluate on (a csv or JSON file).\"},\n",
    "    )\n",
    "    test_file: Optional[str] = field(\n",
    "        default=None,\n",
    "        metadata={\"help\": \"An optional input test data file to predict on (a csv or JSON file).\"},\n",
    "    )\n",
    "    text_column_name: Optional[str] = field(\n",
    "        default=None, metadata={\"help\": \"The column name of text to input in the file (a csv or JSON file).\"}\n",
    "    )\n",
    "    label_column_name: Optional[str] = field(\n",
    "        default=None, metadata={\"help\": \"The column name of label to input in the file (a csv or JSON file).\"}\n",
    "    )\n",
    "    overwrite_cache: bool = field(\n",
    "        default=False, metadata={\"help\": \"Overwrite the cached training and evaluation sets\"}\n",
    "    )\n",
    "    preprocessing_num_workers: Optional[int] = field(\n",
    "        default=None,\n",
    "        metadata={\"help\": \"The number of processes to use for the preprocessing.\"},\n",
    "    )\n",
    "    max_seq_length: int = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": (\n",
    "                \"The maximum total input sequence length after tokenization. If set, sequences longer \"\n",
    "                \"than this will be truncated, sequences shorter will be padded.\"\n",
    "            )\n",
    "        },\n",
    "    )\n",
    "    pad_to_max_length: bool = field(\n",
    "        default=False,\n",
    "        metadata={\n",
    "            \"help\": (\n",
    "                \"Whether to pad all samples to model maximum sentence length. \"\n",
    "                \"If False, will pad the samples dynamically when batching to the maximum length in the batch. More \"\n",
    "                \"efficient on GPU but very bad for TPU.\"\n",
    "            )\n",
    "        },\n",
    "    )\n",
    "    max_train_samples: Optional[int] = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": (\n",
    "                \"For debugging purposes or quicker training, truncate the number of training examples to this \"\n",
    "                \"value if set.\"\n",
    "            )\n",
    "        },\n",
    "    )\n",
    "    max_eval_samples: Optional[int] = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": (\n",
    "                \"For debugging purposes or quicker training, truncate the number of evaluation examples to this \"\n",
    "                \"value if set.\"\n",
    "            )\n",
    "        },\n",
    "    )\n",
    "    max_predict_samples: Optional[int] = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": (\n",
    "                \"For debugging purposes or quicker training, truncate the number of prediction examples to this \"\n",
    "                \"value if set.\"\n",
    "            )\n",
    "        },\n",
    "    )\n",
    "    label_all_tokens: bool = field(\n",
    "        default=False,\n",
    "        metadata={\n",
    "            \"help\": (\n",
    "                \"Whether to put the label for one word on all tokens of generated by that word or just on the \"\n",
    "                \"one (in which case the other tokens will have a padding index).\"\n",
    "            )\n",
    "        },\n",
    "    )\n",
    "    return_entity_level_metrics: bool = field(\n",
    "        default=False,\n",
    "        metadata={\"help\": \"Whether to return all the entity levels during evaluation or just the overall ones.\"},\n",
    "    )\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        if self.dataset_name is None and self.train_file is None and self.validation_file is None:\n",
    "            raise ValueError(\"Need either a dataset name or a training/validation file.\")\n",
    "        else:\n",
    "            if self.train_file is not None:\n",
    "                extension = self.train_file.split(\".\")[-1]\n",
    "                assert extension in [\"csv\", \"json\"], \"`train_file` should be a csv or a json file.\"\n",
    "            if self.validation_file is not None:\n",
    "                extension = self.validation_file.split(\".\")[-1]\n",
    "                assert extension in [\"csv\", \"json\"], \"`validation_file` should be a csv or a json file.\"\n",
    "        self.task_name = self.task_name.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die folgende Klasse erlaubt die Konfiguration des Trainings, insbesondere kann man den Namen des Trainingsdatensets angeben. Für unser Beispiel ist auch `return_entity_level_metrics` relevant – der Defaultwert ist `False`, aber wir möchten diese Auswertung.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(training_args, model_args, data_args):\n",
    "    \n",
    "    # Sending telemetry. Tracking the example usage helps us better allocate resources to maintain them. The\n",
    "    # information sent is the one passed as arguments along with your Python/PyTorch versions.\n",
    "    send_example_telemetry(\"run_ner\", model_args, data_args)\n",
    "\n",
    "    # Setup logging\n",
    "    logging.basicConfig(\n",
    "        format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n",
    "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "        handlers=[logging.StreamHandler(sys.stdout)],\n",
    "    )\n",
    "\n",
    "    if training_args.should_log:\n",
    "        # The default of training_args.log_level is passive, so we set log level at info here to have that default.\n",
    "        transformers.utils.logging.set_verbosity_info()\n",
    "\n",
    "    log_level = training_args.get_process_log_level()\n",
    "    logger.setLevel(log_level)\n",
    "    datasets.utils.logging.set_verbosity(log_level)\n",
    "    transformers.utils.logging.set_verbosity(log_level)\n",
    "    transformers.utils.logging.enable_default_handler()\n",
    "    transformers.utils.logging.enable_explicit_format()\n",
    "\n",
    "    # Log on each process the small summary:\n",
    "    logger.warning(\n",
    "        f\"Process rank: {training_args.local_rank}, device: {training_args.device}, n_gpu: {training_args.n_gpu}\"\n",
    "        + f\"distributed training: {bool(training_args.local_rank != -1)}, 16-bits training: {training_args.fp16}\"\n",
    "    )\n",
    "    logger.info(f\"Training/evaluation parameters {training_args}\")\n",
    "\n",
    "    # Detecting last checkpoint.\n",
    "    last_checkpoint = None\n",
    "    if os.path.isdir(training_args.output_dir) and training_args.do_train and not training_args.overwrite_output_dir:\n",
    "        last_checkpoint = get_last_checkpoint(training_args.output_dir)\n",
    "        if last_checkpoint is None and len(os.listdir(training_args.output_dir)) > 0:\n",
    "            raise ValueError(\n",
    "                f\"Output directory ({training_args.output_dir}) already exists and is not empty. \"\n",
    "                \"Use --overwrite_output_dir to overcome.\"\n",
    "            )\n",
    "        elif last_checkpoint is not None and training_args.resume_from_checkpoint is None:\n",
    "            logger.info(\n",
    "                f\"Checkpoint detected, resuming training at {last_checkpoint}. To avoid this behavior, change \"\n",
    "                \"the `--output_dir` or add `--overwrite_output_dir` to train from scratch.\"\n",
    "            )\n",
    "\n",
    "    # Set seed before initializing model.\n",
    "    set_seed(training_args.seed)\n",
    "\n",
    "    # Get the datasets: you can either provide your own CSV/JSON/TXT training and evaluation files (see below)\n",
    "    # or just provide the name of one of the public datasets available on the hub at https://huggingface.co/datasets/\n",
    "    # (the dataset will be downloaded automatically from the datasets Hub).\n",
    "    #\n",
    "    # For CSV/JSON files, this script will use the column called 'text' or the first column if no column called\n",
    "    # 'text' is found. You can easily tweak this behavior (see below).\n",
    "    #\n",
    "    # In distributed training, the load_dataset function guarantee that only one local process can concurrently\n",
    "    # download the dataset.\n",
    "    if data_args.dataset_name is not None:\n",
    "        # Downloading and loading a dataset from the hub.\n",
    "        raw_datasets = load_dataset(\n",
    "            data_args.dataset_name,\n",
    "            data_args.dataset_config_name,\n",
    "            cache_dir=model_args.cache_dir,\n",
    "            use_auth_token=True if model_args.use_auth_token else None,\n",
    "        )\n",
    "    else:\n",
    "        data_files = {}\n",
    "        if data_args.train_file is not None:\n",
    "            data_files[\"train\"] = data_args.train_file\n",
    "        if data_args.validation_file is not None:\n",
    "            data_files[\"validation\"] = data_args.validation_file\n",
    "        if data_args.test_file is not None:\n",
    "            data_files[\"test\"] = data_args.test_file\n",
    "        extension = data_args.train_file.split(\".\")[-1]\n",
    "        raw_datasets = load_dataset(extension, data_files=data_files, cache_dir=model_args.cache_dir)\n",
    "    # See more about loading any type of standard or custom dataset (from files, python dict, pandas DataFrame, etc) at\n",
    "    # https://huggingface.co/docs/datasets/loading_datasets.html.\n",
    "\n",
    "    if training_args.do_train:\n",
    "        column_names = raw_datasets[\"train\"].column_names\n",
    "        features = raw_datasets[\"train\"].features\n",
    "    else:\n",
    "        column_names = raw_datasets[\"validation\"].column_names\n",
    "        features = raw_datasets[\"validation\"].features\n",
    "\n",
    "    if data_args.text_column_name is not None:\n",
    "        text_column_name = data_args.text_column_name\n",
    "    elif \"tokens\" in column_names:\n",
    "        text_column_name = \"tokens\"\n",
    "    else:\n",
    "        text_column_name = column_names[0]\n",
    "\n",
    "    if data_args.label_column_name is not None:\n",
    "        label_column_name = data_args.label_column_name\n",
    "    elif f\"{data_args.task_name}_tags\" in column_names:\n",
    "        label_column_name = f\"{data_args.task_name}_tags\"\n",
    "    else:\n",
    "        label_column_name = column_names[1]\n",
    "\n",
    "    # In the event the labels are not a `Sequence[ClassLabel]`, we will need to go through the dataset to get the\n",
    "    # unique labels.\n",
    "    def get_label_list(labels):\n",
    "        unique_labels = set()\n",
    "        for label in labels:\n",
    "            unique_labels = unique_labels | set(label)\n",
    "        label_list = list(unique_labels)\n",
    "        label_list.sort()\n",
    "        return label_list\n",
    "\n",
    "    # If the labels are of type ClassLabel, they are already integers and we have the map stored somewhere.\n",
    "    # Otherwise, we have to get the list of labels manually.\n",
    "    labels_are_int = isinstance(features[label_column_name].feature, ClassLabel)\n",
    "    if labels_are_int:\n",
    "        label_list = features[label_column_name].feature.names\n",
    "        label_to_id = {i: i for i in range(len(label_list))}\n",
    "    else:\n",
    "        label_list = get_label_list(raw_datasets[\"train\"][label_column_name])\n",
    "        label_to_id = {l: i for i, l in enumerate(label_list)}\n",
    "\n",
    "    num_labels = len(label_list)\n",
    "\n",
    "    # Load pretrained model and tokenizer\n",
    "    #\n",
    "    # Distributed training:\n",
    "    # The .from_pretrained methods guarantee that only one local process can concurrently\n",
    "    # download model & vocab.\n",
    "    config = AutoConfig.from_pretrained(\n",
    "        model_args.config_name if model_args.config_name else model_args.model_name_or_path,\n",
    "        num_labels=num_labels,\n",
    "        finetuning_task=data_args.task_name,\n",
    "        cache_dir=model_args.cache_dir,\n",
    "        revision=model_args.model_revision,\n",
    "        use_auth_token=True if model_args.use_auth_token else None,\n",
    "    )\n",
    "\n",
    "    tokenizer_name_or_path = model_args.tokenizer_name if model_args.tokenizer_name else model_args.model_name_or_path\n",
    "    if config.model_type in {\"bloom\", \"gpt2\", \"roberta\"}:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\n",
    "            tokenizer_name_or_path,\n",
    "            cache_dir=model_args.cache_dir,\n",
    "            use_fast=True,\n",
    "            revision=model_args.model_revision,\n",
    "            use_auth_token=True if model_args.use_auth_token else None,\n",
    "            add_prefix_space=True,\n",
    "        )\n",
    "    else:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\n",
    "            tokenizer_name_or_path,\n",
    "            cache_dir=model_args.cache_dir,\n",
    "            use_fast=True,\n",
    "            revision=model_args.model_revision,\n",
    "            use_auth_token=True if model_args.use_auth_token else None,\n",
    "        )\n",
    "\n",
    "    model = AutoModelForTokenClassification.from_pretrained(\n",
    "        model_args.model_name_or_path,\n",
    "        from_tf=bool(\".ckpt\" in model_args.model_name_or_path),\n",
    "        config=config,\n",
    "        cache_dir=model_args.cache_dir,\n",
    "        revision=model_args.model_revision,\n",
    "        use_auth_token=True if model_args.use_auth_token else None,\n",
    "        ignore_mismatched_sizes=model_args.ignore_mismatched_sizes,\n",
    "    )\n",
    "\n",
    "    # Tokenizer check: this script requires a fast tokenizer.\n",
    "    if not isinstance(tokenizer, PreTrainedTokenizerFast):\n",
    "        raise ValueError(\n",
    "            \"This example script only works for models that have a fast tokenizer. Checkout the big table of models at\"\n",
    "            \" https://huggingface.co/transformers/index.html#supported-frameworks to find the model types that meet\"\n",
    "            \" this requirement\"\n",
    "        )\n",
    "\n",
    "    # Model has labels -> use them.\n",
    "    if model.config.label2id != PretrainedConfig(num_labels=num_labels).label2id:\n",
    "        if sorted(model.config.label2id.keys()) == sorted(label_list):\n",
    "            # Reorganize `label_list` to match the ordering of the model.\n",
    "            if labels_are_int:\n",
    "                label_to_id = {i: int(model.config.label2id[l]) for i, l in enumerate(label_list)}\n",
    "                label_list = [model.config.id2label[i] for i in range(num_labels)]\n",
    "            else:\n",
    "                label_list = [model.config.id2label[i] for i in range(num_labels)]\n",
    "                label_to_id = {l: i for i, l in enumerate(label_list)}\n",
    "        else:\n",
    "            logger.warning(\n",
    "                \"Your model seems to have been trained with labels, but they don't match the dataset: \",\n",
    "                f\"model labels: {sorted(model.config.label2id.keys())}, dataset labels:\"\n",
    "                f\" {sorted(label_list)}.\\nIgnoring the model labels as a result.\",\n",
    "            )\n",
    "\n",
    "    # Set the correspondences label/ID inside the model config\n",
    "    model.config.label2id = {l: i for i, l in enumerate(label_list)}\n",
    "    model.config.id2label = dict(enumerate(label_list))\n",
    "\n",
    "    # Map that sends B-Xxx label to its I-Xxx counterpart\n",
    "    b_to_i_label = []\n",
    "    for idx, label in enumerate(label_list):\n",
    "        if label.startswith(\"B-\") and label.replace(\"B-\", \"I-\") in label_list:\n",
    "            b_to_i_label.append(label_list.index(label.replace(\"B-\", \"I-\")))\n",
    "        else:\n",
    "            b_to_i_label.append(idx)\n",
    "\n",
    "    # Preprocessing the dataset\n",
    "    # Padding strategy\n",
    "    padding = \"max_length\" if data_args.pad_to_max_length else False\n",
    "\n",
    "    # Tokenize all texts and align the labels with them.\n",
    "    def tokenize_and_align_labels(examples):\n",
    "        tokenized_inputs = tokenizer(\n",
    "            examples[text_column_name],\n",
    "            padding=padding,\n",
    "            truncation=True,\n",
    "            max_length=data_args.max_seq_length,\n",
    "            # We use this argument because the texts in our dataset are lists of words (with a label for each word).\n",
    "            is_split_into_words=True,\n",
    "        )\n",
    "        labels = []\n",
    "        for i, label in enumerate(examples[label_column_name]):\n",
    "            word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "            previous_word_idx = None\n",
    "            label_ids = []\n",
    "            for word_idx in word_ids:\n",
    "                # Special tokens have a word id that is None. We set the label to -100 so they are automatically\n",
    "                # ignored in the loss function.\n",
    "                if word_idx is None:\n",
    "                    label_ids.append(-100)\n",
    "                # We set the label for the first token of each word.\n",
    "                elif word_idx != previous_word_idx:\n",
    "                    label_ids.append(label_to_id[label[word_idx]])\n",
    "                # For the other tokens in a word, we set the label to either the current label or -100, depending on\n",
    "                # the label_all_tokens flag.\n",
    "                else:\n",
    "                    if data_args.label_all_tokens:\n",
    "                        label_ids.append(b_to_i_label[label_to_id[label[word_idx]]])\n",
    "                    else:\n",
    "                        label_ids.append(-100)\n",
    "                previous_word_idx = word_idx\n",
    "\n",
    "            labels.append(label_ids)\n",
    "        tokenized_inputs[\"labels\"] = labels\n",
    "        return tokenized_inputs\n",
    "\n",
    "    if training_args.do_train:\n",
    "        if \"train\" not in raw_datasets:\n",
    "            raise ValueError(\"--do_train requires a train dataset\")\n",
    "        train_dataset = raw_datasets[\"train\"]\n",
    "        if data_args.max_train_samples is not None:\n",
    "            max_train_samples = min(len(train_dataset), data_args.max_train_samples)\n",
    "            train_dataset = train_dataset.select(range(max_train_samples))\n",
    "        with training_args.main_process_first(desc=\"train dataset map pre-processing\"):\n",
    "            train_dataset = train_dataset.map(\n",
    "                tokenize_and_align_labels,\n",
    "                batched=True,\n",
    "                num_proc=data_args.preprocessing_num_workers,\n",
    "                load_from_cache_file=not data_args.overwrite_cache,\n",
    "                desc=\"Running tokenizer on train dataset\",\n",
    "            )\n",
    "\n",
    "    if training_args.do_eval:\n",
    "        if \"validation\" not in raw_datasets:\n",
    "            raise ValueError(\"--do_eval requires a validation dataset\")\n",
    "        eval_dataset = raw_datasets[\"validation\"]\n",
    "        if data_args.max_eval_samples is not None:\n",
    "            max_eval_samples = min(len(eval_dataset), data_args.max_eval_samples)\n",
    "            eval_dataset = eval_dataset.select(range(max_eval_samples))\n",
    "        with training_args.main_process_first(desc=\"validation dataset map pre-processing\"):\n",
    "            eval_dataset = eval_dataset.map(\n",
    "                tokenize_and_align_labels,\n",
    "                batched=True,\n",
    "                num_proc=data_args.preprocessing_num_workers,\n",
    "                load_from_cache_file=not data_args.overwrite_cache,\n",
    "                desc=\"Running tokenizer on validation dataset\",\n",
    "            )\n",
    "\n",
    "    if training_args.do_predict:\n",
    "        if \"test\" not in raw_datasets:\n",
    "            raise ValueError(\"--do_predict requires a test dataset\")\n",
    "        predict_dataset = raw_datasets[\"test\"]\n",
    "        if data_args.max_predict_samples is not None:\n",
    "            max_predict_samples = min(len(predict_dataset), data_args.max_predict_samples)\n",
    "            predict_dataset = predict_dataset.select(range(max_predict_samples))\n",
    "        with training_args.main_process_first(desc=\"prediction dataset map pre-processing\"):\n",
    "            predict_dataset = predict_dataset.map(\n",
    "                tokenize_and_align_labels,\n",
    "                batched=True,\n",
    "                num_proc=data_args.preprocessing_num_workers,\n",
    "                load_from_cache_file=not data_args.overwrite_cache,\n",
    "                desc=\"Running tokenizer on prediction dataset\",\n",
    "            )\n",
    "\n",
    "    # Data collator\n",
    "    data_collator = DataCollatorForTokenClassification(tokenizer, pad_to_multiple_of=8 if training_args.fp16 else None)\n",
    "\n",
    "    # Metrics\n",
    "    metric = evaluate.load(\"seqeval\")\n",
    "\n",
    "    def compute_metrics(p):\n",
    "        predictions, labels = p\n",
    "        predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "        # Remove ignored index (special tokens)\n",
    "        true_predictions = [\n",
    "            [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "            for prediction, label in zip(predictions, labels)\n",
    "        ]\n",
    "        true_labels = [\n",
    "            [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "            for prediction, label in zip(predictions, labels)\n",
    "        ]\n",
    "\n",
    "        results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "        if data_args.return_entity_level_metrics:\n",
    "            # Unpack nested dictionaries\n",
    "            final_results = {}\n",
    "            for key, value in results.items():\n",
    "                if isinstance(value, dict):\n",
    "                    for n, v in value.items():\n",
    "                        final_results[f\"{key}_{n}\"] = v\n",
    "                else:\n",
    "                    final_results[key] = value\n",
    "            return final_results\n",
    "        else:\n",
    "            return {\n",
    "                \"precision\": results[\"overall_precision\"],\n",
    "                \"recall\": results[\"overall_recall\"],\n",
    "                \"f1\": results[\"overall_f1\"],\n",
    "                \"accuracy\": results[\"overall_accuracy\"],\n",
    "            }\n",
    "\n",
    "    # Initialize our Trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset if training_args.do_train else None,\n",
    "        eval_dataset=eval_dataset if training_args.do_eval else None,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    # Training\n",
    "    if training_args.do_train:\n",
    "        checkpoint = None\n",
    "        if training_args.resume_from_checkpoint is not None:\n",
    "            checkpoint = training_args.resume_from_checkpoint\n",
    "        elif last_checkpoint is not None:\n",
    "            checkpoint = last_checkpoint\n",
    "        train_result = trainer.train(resume_from_checkpoint=checkpoint)\n",
    "        metrics = train_result.metrics\n",
    "        trainer.save_model()  # Saves the tokenizer too for easy upload\n",
    "\n",
    "        max_train_samples = (\n",
    "            data_args.max_train_samples if data_args.max_train_samples is not None else len(train_dataset)\n",
    "        )\n",
    "        metrics[\"train_samples\"] = min(max_train_samples, len(train_dataset))\n",
    "\n",
    "        trainer.log_metrics(\"train\", metrics)\n",
    "        trainer.save_metrics(\"train\", metrics)\n",
    "        trainer.save_state()\n",
    "\n",
    "    # Evaluation\n",
    "    if training_args.do_eval:\n",
    "        logger.info(\"*** Evaluate ***\")\n",
    "\n",
    "        metrics = trainer.evaluate()\n",
    "\n",
    "        max_eval_samples = data_args.max_eval_samples if data_args.max_eval_samples is not None else len(eval_dataset)\n",
    "        metrics[\"eval_samples\"] = min(max_eval_samples, len(eval_dataset))\n",
    "\n",
    "        trainer.log_metrics(\"eval\", metrics)\n",
    "        trainer.save_metrics(\"eval\", metrics)\n",
    "\n",
    "    # Predict\n",
    "    if training_args.do_predict:\n",
    "        logger.info(\"*** Predict ***\")\n",
    "\n",
    "        predictions, labels, metrics = trainer.predict(predict_dataset, metric_key_prefix=\"predict\")\n",
    "        predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "        # Remove ignored index (special tokens)\n",
    "        true_predictions = [\n",
    "            [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "            for prediction, label in zip(predictions, labels)\n",
    "        ]\n",
    "\n",
    "        trainer.log_metrics(\"predict\", metrics)\n",
    "        trainer.save_metrics(\"predict\", metrics)\n",
    "\n",
    "        # Save predictions\n",
    "        output_predictions_file = os.path.join(training_args.output_dir, \"predictions.txt\")\n",
    "        if trainer.is_world_process_zero():\n",
    "            with open(output_predictions_file, \"w\") as writer:\n",
    "                for prediction in true_predictions:\n",
    "                    writer.write(\" \".join(prediction) + \"\\n\")\n",
    "\n",
    "    kwargs = {\"finetuned_from\": model_args.model_name_or_path, \"tasks\": \"token-classification\"}\n",
    "    if data_args.dataset_name is not None:\n",
    "        kwargs[\"dataset_tags\"] = data_args.dataset_name\n",
    "        if data_args.dataset_config_name is not None:\n",
    "            kwargs[\"dataset_args\"] = data_args.dataset_config_name\n",
    "            kwargs[\"dataset\"] = f\"{data_args.dataset_name} {data_args.dataset_config_name}\"\n",
    "        else:\n",
    "            kwargs[\"dataset\"] = data_args.dataset_name\n",
    "\n",
    "    if training_args.push_to_hub:\n",
    "        trainer.push_to_hub(**kwargs)\n",
    "    else:\n",
    "        trainer.create_model_card(**kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Konfiguration des Trainings\n",
    "\n",
    "Hier wird es spannend! Wählen Sie ein passendes Modell aus und trainieren Sie es.\n",
    "\n",
    "- Beobachten Sie, wie gut das Modell im Vergleich zu den Ergebnissen beim *GermEval 2014* abschneidet. \n",
    "- Was fällt Ihnen im Trainingsverlauf auf? Was können Sie ggf. tun, um die Ergebnisse zu verbessern?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"<choose model>\"\n",
    "output_dir = \"models/germeval_2014\"\n",
    "\n",
    "data_args = DataTrainingArguments(dataset_name=\"germeval_14\", return_entity_level_metrics=True)\n",
    "model_args = ModelArguments(model_name_or_path=model_path)\n",
    "training_args = TrainingArguments(output_dir, num_train_epochs=2, evaluation_strategy=\"steps\", fp16=True, eval_steps=200, do_train=True, do_eval=True, do_predict=True, per_device_train_batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main(training_args, model_args, data_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": true,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
