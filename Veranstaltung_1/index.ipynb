{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21dc3826-60ec-46e9-b914-0d4cfc14a7aa",
   "metadata": {},
   "source": [
    "# Textklassifikation\n",
    "\n",
    "Die Klassifikation von Texten ist einer der zentralen Anwendungsf√§lle von NLP. \n",
    "Er begegnet uns st√§ndig, etwa in Form eines Spam-Filters in unserem Email-Client oder bei der Intent-Erkennung bei einem Sprachassistenten.\n",
    "\n",
    "Gleichzeitig eignet sich die Textklassifikation als Beispiel daf√ºr, welche Fortschritte in den letzten Jahren im Bereich NLP gemacht wurden,\n",
    "etwa bei der Vektorisierung mit *Word2Vec* oder dem Einsatz von transformer-basierten Modellen wie *BERT*.\n",
    "\n",
    "Wir werden als Beispiel die Daten aus dem Wettbewerb *GermEval 2018* (s. `../data/GermEval-2018`) verwenden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560aea75-962a-411f-8155-1922c406a2b5",
   "metadata": {},
   "source": [
    "## Aufgabe 1: Lesen & Aufbereiten der Texte\n",
    "\n",
    "Um die Texte zu klassifizieren, m√ºssen wir die Trainingsdaten lesen und aufbereiten. Schauen Sie sich dazu zun√§chst die ersten 10 Trainingsdatens√§tze an (s. folgende Zelle)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d034bd57-8451-4706-b457-112555fdeb4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@corinnamilborn Liebe Corinna, wir w√ºrden dich gerne als Moderatorin f√ºr uns gewinnen! W√§rst du begeisterbar?\tOTHER\tOTHER\n",
      "@Martin28a Sie haben ja auch Recht. Unser Tweet war etwas missverst√§ndlich. Dass das BVerfG Sachleistungen nicht ausschlie√üt, kritisieren wir.\tOTHER\tOTHER\n",
      "@ahrens_theo fr√∂hlicher gru√ü aus der sch√∂nsten stadt der welt theo ‚öìÔ∏è\tOTHER\tOTHER\n",
      "@dushanwegner Amis h√§tten alles und jeden gew√§hlt...nur Hillary wollten sie nicht und eine Fortsetzung von Obama-Politik erst recht nicht..!\tOTHER\tOTHER\n",
      "@spdde kein verl√§√ülicher Verhandlungspartner. Nachkarteln nach den Sondierzngsgespr√§chen - schickt diese St√ºmper #SPD in die Versenkung.\tOFFENSE\tINSULT\n",
      "@Dirki_M Ja, aber wo widersprechen die Zahlen denn denen, die im von uns verlinkten Artikel stehen? In unserem Tweet geht es rein um subs. Gesch√ºtzte. 2017 ist der gesamte Familiennachzug im Vergleich zu 2016 - die Zahlen, die Hr. Brandner bem√ºht - √ºbrigens leicht r√ºckl√§ufig gewesen.\tOTHER\tOTHER\n",
      "@milenahanm 33 bis 45 habe ich noch gar nicht gelebt und es geht mir am Arsch vorbei was in dieser Zeit geschehen ist. Ich lebe im heute und jetzt und nicht in der Vergangenheit.\tOFFENSE\tPROFANITY\n",
      "@jayxderxmensch @jayxthexhuman Wieso? Was findest du da unklar?\tOTHER\tOTHER\n",
      "@tagesschau Euere AfD Hetze wirkt. Da k√∂nnt ihr stolz sein bei #ARD-Fernsehen\tOFFENSE\tABUSE\n",
      "Deutsche Medien, Halbwahrheiten und einseitige Betrachtung, wie bei allen vom Staat finanzierten \"billigen\" Propagandainstitutionen üòú\tOFFENSE\tABUSE\n"
     ]
    }
   ],
   "source": [
    "!head -10 ../data/GermEval-2018/germeval2018.training.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6dded17-a8cb-4ea0-9abb-0b74ab9fde0e",
   "metadata": {},
   "source": [
    "### Aufgabe 1.1: Auff√§lligkeiten in den Texten\n",
    "\n",
    "Was f√§llt Ihnen an den Texten auf? Welche Bestandteile sollten ggf. aus den Trainingsdaten entfernt werden, da sie das Training verf√§lschen w√ºrden?\n",
    "Welche anderen Bereinigungen k√∂nnten sinnvoll sein?\n",
    "\n",
    "> üí° **Tipp:** \n",
    "> Fragen Sie gerne auch ChatGPT, was man bei der Bereinigung der Texte tun sollte. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a01a7a-7ace-4b95-85bd-02d9910bc0a1",
   "metadata": {},
   "source": [
    "### Aufgabe 1.2: Lesen der Trainings- und Testdatens√§tze\n",
    "\n",
    "Die Trainingsdaten liegen als Textdatei mit drei durch `TAB` getrennten Spalten vor.\n",
    "\n",
    "| TEXT | COARSE | FINE |\n",
    "| ---- | ------ | ---- |\n",
    "| @corinnamilborn Liebe Corinna, wir w√ºrden dich gerne als Moderatorin f√ºr uns gewinnen! W√§rst du begeisterbar?  | OTHER | OTHER |\n",
    "| @Martin28a Sie haben ja auch Recht. Unser Tweet war etwas missverst√§ndlich. Dass das BVerfG Sachleistungen nicht ausschlie√üt, kritisieren wir. | OTHER | OTHER |\n",
    "| @ahrens_theo fr√∂hlicher gru√ü aus der sch√∂nsten stadt der welt theo ‚öìÔ∏è | OTHER | OTHER |\n",
    "| @dushanwegner Amis h√§tten alles und jeden gew√§hlt...nur Hillary wollten sie nicht und eine Fortsetzung von Obama-Politik erst recht nicht..! | OTHER | OTHER |\n",
    "| @spdde kein verl√§√ülicher Verhandlungspartner. Nachkarteln nach den Sondierzngsgespr√§chen - schickt diese St√ºmper #SPD in die Versenkung. | OFFENSE | INSULT | \n",
    "\n",
    "Lesen Sie die Daten und wandeln Sie ihn in eine Liste von `namedtuple` mit den Feldern `text`, `coarse_label` und `fine_label` um.\n",
    "\n",
    "> üí° **Tipp:** \n",
    "> ChatGPT kann Ihnen beim Code sicher helfen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee3f5a86-5bd9-423b-92b4-08556bc74295",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataItem(text='@Martin28a Sie haben ja auch Recht. Unser Tweet war etwas missverst√§ndlich. Dass das BVerfG Sachleistungen nicht ausschlie√üt, kritisieren wir.', coarse_label='OTHER', fine_label='OTHER')\n",
      "DataItem(text='@ahrens_theo fr√∂hlicher gru√ü aus der sch√∂nsten stadt der welt theo ‚öìÔ∏è', coarse_label='OTHER', fine_label='OTHER')\n",
      "DataItem(text='@dushanwegner Amis h√§tten alles und jeden gew√§hlt...nur Hillary wollten sie nicht und eine Fortsetzung von Obama-Politik erst recht nicht..!', coarse_label='OTHER', fine_label='OTHER')\n",
      "DataItem(text='@spdde kein verl√§√ülicher Verhandlungspartner. Nachkarteln nach den Sondierzngsgespr√§chen - schickt diese St√ºmper #SPD in die Versenkung.', coarse_label='OFFENSE', fine_label='INSULT')\n",
      "DataItem(text='@Dirki_M Ja, aber wo widersprechen die Zahlen denn denen, die im von uns verlinkten Artikel stehen? In unserem Tweet geht es rein um subs. Gesch√ºtzte. 2017 ist der gesamte Familiennachzug im Vergleich zu 2016 - die Zahlen, die Hr. Brandner bem√ºht - √ºbrigens leicht r√ºckl√§ufig gewesen.', coarse_label='OTHER', fine_label='OTHER')\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from collections import namedtuple\n",
    "\n",
    "# Schritt 2: Definieren des namedtuple\n",
    "DataItem = namedtuple('DataItem', ['text', 'coarse_label', 'fine_label'])\n",
    "\n",
    "# Erstellen einer leeren Liste, um die Datenitems zu speichern\n",
    "data_items = []\n",
    "\n",
    "# Schritt 3: Lesen der Datei\n",
    "with open('../data/GermEval-2018/germeval2018.training.txt', 'r', encoding='utf-8') as file:\n",
    "    reader = csv.reader(file, delimiter='\\t')\n",
    "    next(reader)  # √úberspringen der Kopfzeile\n",
    "    for row in reader:\n",
    "        if row:  # Sicherstellen, dass die Zeile nicht leer ist\n",
    "            item = DataItem(text=row[0], coarse_label=row[1], fine_label=row[2])\n",
    "            data_items.append(item)\n",
    "\n",
    "# Ausgeben der ersten 5 Datenelemente zur √úberpr√ºfung\n",
    "for item in data_items[:5]:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0e4a9d-647e-482c-b7ef-6b9c85b7b810",
   "metadata": {},
   "source": [
    "### Aufgabe 1.3: Bereinigung der Trainingsdatens√§tze\n",
    "\n",
    "Setzen Sie **mindestens** die folgenden Textbereinigungen um:\n",
    "\n",
    "- Entfernen von *Twitter-Handles* wie `@corinnamilborn` (Warum ist das sinnvoll?)\n",
    "- Entfernen des Hashtag-Zeichens `#` (Warum ist das sinnvoll?)\n",
    "\n",
    "Zus√§tzlich k√∂nnen Sie mit anderen Bereinigungen experimentieren (Entfernung Gro√ü- und Kleinschreibung, Stemming, ...). Im Deutschen bringt das allerdings nicht so viel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e74da21b-1bfa-4a1a-bcfa-bf0a9bda6845",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataItem(text='sie haben ja auch recht. unser tweet war etwas missverst√§ndlich. dass das bverfg sachleistungen nicht ausschlie√üt, kritisieren wir.', coarse_label='OTHER', fine_label='OTHER')\n",
      "DataItem(text='fr√∂hlicher gru√ü aus der sch√∂nsten stadt der welt theo ‚öìÔ∏è', coarse_label='OTHER', fine_label='OTHER')\n",
      "DataItem(text='amis h√§tten alles und jeden gew√§hlt...nur hillary wollten sie nicht und eine fortsetzung von obama-politik erst recht nicht..!', coarse_label='OTHER', fine_label='OTHER')\n",
      "DataItem(text='kein verl√§√ülicher verhandlungspartner. nachkarteln nach den sondierzngsgespr√§chen - schickt diese st√ºmper spd in die versenkung.', coarse_label='OFFENSE', fine_label='INSULT')\n",
      "DataItem(text='ja, aber wo widersprechen die zahlen denn denen, die im von uns verlinkten artikel stehen? in unserem tweet geht es rein um subs. gesch√ºtzte. 2017 ist der gesamte familiennachzug im vergleich zu 2016 - die zahlen, die hr. brandner bem√ºht - √ºbrigens leicht r√ºckl√§ufig gewesen.', coarse_label='OTHER', fine_label='OTHER')\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import re\n",
    "from collections import namedtuple\n",
    "\n",
    "# Schritt 2: Definition des namedtuple\n",
    "DataItem = namedtuple('DataItem', ['text', 'coarse_label', 'fine_label'])\n",
    "\n",
    "data_items = []\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'@\\w+', '', text)  # Entfernen von Twitter-Handles\n",
    "    text = re.sub(r'#', '', text)  # Entfernen von Hashtag-Zeichen\n",
    "    # Hier k√∂nnen Sie weitere Bereinigungen hinzuf√ºgen\n",
    "    text = text.lower()  # Optional: Umwandlung in Kleinbuchstaben\n",
    "    return text.strip()\n",
    "\n",
    "with open('../data/GermEval-2018/germeval2018.training.txt', 'r', encoding='utf-8') as file:\n",
    "    reader = csv.reader(file, delimiter='\\t')\n",
    "    next(reader)  # √úberspringen der Kopfzeile\n",
    "    for row in reader:\n",
    "        if row:  # Sicherstellen, dass die Zeile nicht leer ist\n",
    "            cleaned_text = clean_text(row[0])\n",
    "            item = DataItem(text=cleaned_text, coarse_label=row[1], fine_label=row[2])\n",
    "            data_items.append(item)\n",
    "\n",
    "# Die ersten 5 Datenelemente ausgeben\n",
    "for item in data_items[:5]:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca16b3aa-039e-4f6e-9248-f81666a1657e",
   "metadata": {},
   "source": [
    "### Aufgabe 1.4: Training eines Naive-Bayes-Klassifikators\n",
    "\n",
    "Mithilfe von `scikit-learn` ist es sehr einfach, eine Naive-Bayes-Klassifikator zu trainieren. Sie ben√∂tigen im einfachsten Fall nur den\n",
    "[`CountVectorizer`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) zur Vektorisierung und \n",
    "[`MultinomialNB`](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html) f√ºr die Klassifikation zu einer Pipeline zu verbinden.\n",
    "\n",
    "> üí° **Tipp:** \n",
    "> Auch hier kann ChatGPT Ihnen beim Code helfen ...\n",
    "\n",
    "Trainieren Sie den Klassifikator auf den Trainingsdaten und messen Sie die Accuracy auf den Testdaten. Wie gut ist Ihr Ergebnis? Vergleichen Sie Ihr Ergebnis mit den [Ergebnissen des GermEval-2018](../data/GermEval-2018/results.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95a2f351-30b1-453f-8a1e-61bc5911a45d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.781437125748503\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Nehmen wir an, `data_items` ist Ihre Liste von DataItem namedtuples\n",
    "texts = [item.text for item in data_items]\n",
    "labels = [item.coarse_label for item in data_items]\n",
    "\n",
    "# Teilen der Daten in Training- und Testdaten\n",
    "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Erstellen der Pipeline\n",
    "pipeline = make_pipeline(CountVectorizer(), MultinomialNB())\n",
    "\n",
    "# Training des Klassifikators\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Vorhersagen machen\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Genauigkeit bewerten\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "275381c4-050a-4d4d-b6e0-d2a7878bdb15",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro Average F1 Score: 0.7152799673030887\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# F1-Score berechnen\n",
    "f1 = f1_score(y_test, y_pred, average='macro')  # 'macro' gibt an, dass der Durchschnitt √ºber die Labels ungewichtet genommen wird.\n",
    "\n",
    "print(f\"Macro Average F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df86d69e-377b-4c26-886c-cf54febbbd8f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7292525014714538\n",
      "Macro Average F1 Score: 0.6516265288756292\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Pfad zu den Dateien\n",
    "train_file_path = '../data/GermEval-2018/germeval2018.training.txt'\n",
    "test_file_path = '../data/GermEval-2018/germeval2018.test.txt'\n",
    "\n",
    "def load_data(file_path):\n",
    "    texts, labels = [], []\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        reader = csv.reader(file, delimiter='\\t')\n",
    "        for row in reader:\n",
    "            if row:  # Sicherstellen, dass die Zeile nicht leer ist\n",
    "                texts.append(row[0])\n",
    "                labels.append(row[1])  # M√∂glicherweise m√ºssen Sie dies an Ihre spezifische Label-Spalte anpassen\n",
    "    return texts, labels\n",
    "\n",
    "# Laden der Trainings- und Testdaten\n",
    "X_train, y_train = load_data(train_file_path)\n",
    "X_test, y_test = load_data(test_file_path)\n",
    "\n",
    "# Pipeline erstellen und Training\n",
    "pipeline = make_pipeline(CountVectorizer(), MultinomialNB())\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Vorhersage und Bewertung\n",
    "y_pred = pipeline.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Macro Average F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8c75942-2584-4884-a3f1-ca4fcadb500f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e2e47b-e8da-42ec-a49a-b78f0324cae5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
