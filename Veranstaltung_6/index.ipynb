{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "026d9515-158a-4913-b76b-fa006bfd58c3",
   "metadata": {},
   "source": [
    "## RAG-basierter ChatBot zu den Parteiprogrammen zur Bundestagswahl 2025\n",
    "\n",
    "In dieser Übung untersuchen wir die Parteiprogramme zur Bundestagswahl 2025 mithilfe von `langchain` und entwickeln einen ChatBot, dem wir Fragen zu den Programmen stellen können."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e296001-691e-4c6e-adc4-c8bee8fa2d09",
   "metadata": {},
   "source": [
    "### Installation der benötigten Pakete\n",
    "\n",
    "Neben diversen `langchain` Paketen benötigen wir `unstructured` zum Lesen der PDF-Dateien und ChromaDB als Vektordatenbank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12173a6-5ea9-4525-a9c2-3edd00480bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --upgrade --quiet dotenv langchain langchain-community langchain_chroma langchain_openai langchain_unstructured  unstructured[pdf] chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9b4bee-903a-4f70-9562-66b2bf201d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b428fe86-f450-420d-99d0-a139946f67a8",
   "metadata": {},
   "source": [
    "Die folgende Zelle lädt benötigte Umgebungsvariablen, u.a. einen Lizenzschlüssel für OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fca6863-c4e3-4111-87a7-bdf150624220",
   "metadata": {},
   "outputs": [],
   "source": [
    "%dotenv /home/archive/nlp/.env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259aad1e-fa40-44be-b709-8815d7587a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from typing import List\n",
    "from collections.abc import Mapping\n",
    "\n",
    "from langchain_core.retrievers import BaseRetriever\n",
    "from langchain_core.callbacks.manager import CallbackManagerForRetrieverRun\n",
    "from langchain_core.vectorstores.base import VectorStore\n",
    "from langchain_core.embeddings.embeddings import Embeddings\n",
    "from langchain_core.documents.base import Document\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader, Docx2txtLoader\n",
    "from langchain_unstructured.document_loaders import UnstructuredLoader\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "from langchain.retrievers import MergerRetriever\n",
    "from langchain.retrievers.document_compressors.flashrank_rerank import FlashrankRerank\n",
    "from langchain.retrievers.contextual_compression import ContextualCompressionRetriever\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "from unstructured.chunking.title import chunk_by_title\n",
    "from unstructured.chunking.basic import chunk_elements\n",
    "from unstructured.documents.elements import Image\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "DATABASE_PATH = \"./chroma/\"\n",
    "EMBEDDING_MODEL = \"text-embedding-3-small\"\n",
    "\n",
    "def pretty_output(chunks, mode: str):\n",
    "    if mode == \"elements\":\n",
    "        for i, chunk in enumerate(chunks, 1):\n",
    "            print(f\"Chunk {i}:\")\n",
    "            print(chunk.text)\n",
    "            print(\"-\" * 120)\n",
    "            \n",
    "    elif mode == \"documents\":\n",
    "        for i, chunk in enumerate(chunks, 1):\n",
    "            print(f\"Chunk {i}:\")\n",
    "            print(chunk.page_content)\n",
    "            print(\"-\" * 120)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bca573b-5300-4af3-a4a5-323e5774cc04",
   "metadata": {},
   "source": [
    "### Lesen der Wahlprogramme\n",
    "\n",
    "Folgende Parteiprogramme liegen vor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ba3d57-9b81-4bfb-8c73-7bfdddfcceb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = {\n",
    "    \"BSW\": \"BSW_Parteiprogramm.pdf\",\n",
    "    \"Grüne\": \"Grüne_BTW2025.pdf\",\n",
    "    \"CDU\": \"CDU_BTW2025.pdf\",\n",
    "    \"AfD\": \"Programm_AfD_Online_.pdf\",\n",
    "    \"Linke\": \"DIE_LINKE_Wahlprogramm_zur_Bundestagswahl_2021.pdf\",\n",
    "    \"SPD\": \"SPD-Zukunftsprogramm.pdf\",\n",
    "    \"FDP\": \"fdp-wahlprogramm_2025.pdf\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35119b9-3363-4d00-ae9f-83c11a8bb97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "\n",
    "# Chunker 2\n",
    "max_characters = 5000\n",
    "new_after_n_chars = 1500\n",
    "overlap = 1000\n",
    "combine_text_under_n_chars_multiplier=int(new_after_n_chars*(2/3))\n",
    "\n",
    "DOCS = []\n",
    "\n",
    "for (party, fpath) in docs.items():\n",
    "    chunks = UnstructuredLoader(\n",
    "        file_path=path.join(\"data\", fpath),\n",
    "        languages=[\"deu\"],\n",
    "        chunking_strategy=\"by_title\",\n",
    "        max_characters=max_characters,\n",
    "        overlap=overlap,\n",
    "        overlap_all=True,\n",
    "        combine_text_under_n_chars=combine_text_under_n_chars_multiplier,\n",
    "        new_after_n_chars=new_after_n_chars,\n",
    "    ).load()\n",
    "\n",
    "    # Füge Partei als Metadatenfeld hinzu\n",
    "    for chunk in chunks:\n",
    "        chunk.metadata[\"party\"] = party\n",
    "    DOCS += chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6b6a54-5f87-4997-9a17-0b6a30ede30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(DOCS), DOCS[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79294d7e-799b-4401-9eb3-49af3f077e9e",
   "metadata": {},
   "source": [
    "Patchen der Metadaten: Chroma akzeptiert nur Strings als Metadaten, `unstructured` liefert allerdings eine *Liste* erkannter Sprachen. Diese Liste wandeln wir in einen String um."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5986e173-6fb4-404c-ab7c-7392d6d16f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "for chunk in DOCS:\n",
    "    for md in chunk.metadata:\n",
    "        if isinstance(chunk.metadata[md], list):\n",
    "            chunk.metadata[md] = str(chunk.metadata[md])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbfad94-b788-47a0-9bac-cfd26f13efa9",
   "metadata": {},
   "source": [
    "### Speichern der Dokumente in ChromaDB\n",
    "\n",
    "Normalerweise würden wir jetzt die Documente mithilfe des *Embedding-Model* in der Vektordatenbank `chroma` speichern:\n",
    "\n",
    "```Python\n",
    "client = chromadb.PersistentClient(\n",
    "    path=os.path.join(DATABASE_PATH, f\"{EMBEDDING_MODEL}\"),\n",
    ")\n",
    "\n",
    "Chroma.from_documents(\n",
    "    documents=DOCS,\n",
    "    embedding=OpenAIEmbeddings(api_key=OPENAI_API_KEY, model=EMBEDDING_MODEL, chunk_size=300),\n",
    "    client=client,\n",
    "    collection_name=f\"BTW2025\",\n",
    ")\n",
    "```\n",
    "\n",
    "Diesen Schritt ersparen wir uns, da er Kosten erzeugt und es reicht, die Vektordatenbank einmal zu füllen. Für die weiteren Schritte verwenden wir eine \"fertige\" Datenbank im Verzeichnis `chroma`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6851a017-8096-4fb0-87a9-9b76b9cf4d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = chromadb.PersistentClient(\n",
    "    path=os.path.join(DATABASE_PATH, f\"{EMBEDDING_MODEL}\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae70023a-46a6-41c0-b2f1-88ba8940c564",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.list_collections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a896bf0e-5601-4139-a8f5-73947505b992",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = Chroma(\n",
    "        collection_name=f\"BTW2025\",\n",
    "        client=client,\n",
    "        embedding_function=OpenAIEmbeddings(model=EMBEDDING_MODEL, api_key=OPENAI_API_KEY),\n",
    "        create_collection_if_not_exists=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3184e3b7-460a-459e-b4f9-a81e689ee724",
   "metadata": {},
   "source": [
    "### Erstellen des Prompt Templates\n",
    "\n",
    "Die folgende Zelle erstellt das `PromptTemplate` zur Beantwortung der Benutzerfragen.\n",
    "Passen Sie das Template gerne nach Ihren Vorstellungen an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6dde1f-23ed-48e9-bba5-7e4389c277c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLM = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.0,\n",
    ")\n",
    "\n",
    "PROMPT = ChatPromptTemplate([\n",
    "    (\"system\", \"\"\"Du bist ein Experte für politische Fragen zur Bundestagswahl und beantwortest die Fragen der Benutzer auf Basis des bereitgestellten Kontext. \n",
    "Der Kontext besteht aus eine Aufstellung der Aussagen einzelner Parteien zu der Fragestellung des Benutzers.\n",
    "\n",
    "- Wenn die Frage anhand des Kontext beantwortet werden kann, gib in Deiner Antwort jeweils an, zu welcher Partei eine Aussage gehört.\n",
    "- Wenn es Aussagen mehrerer Parteien gibt, stelle die Aussagen der Parteien gegenüber und verdeutliche die Unterschieder der Parteien.\n",
    "- Wenn die Frage im Kontext nicht eindeutig beantwortet werden kann oder keine ausreichenden Informationen vorliegen, gib an, dass du die Frage nicht beantworten kannst.\n",
    "- Achte besonders darauf, dass du keine Informationen hinzufügst, die nicht im Kontext enthalten sind.\n",
    "- Gib am Ende Zitate aus den Aussagen der Parteien an, die Deine Zusammenfassung nachvollziehbar machen.\n",
    "\n",
    "Wenn in der Frage nach der Position einer bestimmten Partei gefragt wird, gehe in der Antwort auf diese Partei ein.\n",
    "Wenn in der Frage keine Partei explizit erwähnt wird, erstelle eine Übersicht der Positionen der folgenden Parteien:\n",
    "- CDU\n",
    "- SPD\n",
    "- Grüne\n",
    "- AfD\n",
    "- FDP\n",
    "- BSW\n",
    "- Linke\n",
    "\n",
    "Am Ende deiner Antwort weise bitte darauf hin, dass du ein ChatBot bist und die Antwort unbedingt anhand der Quellen überprüft werden sollte.\n",
    "\n",
    "<kontext>\n",
    "{context}\n",
    "</kontext>\"\"\"),\n",
    "    (\"human\", \"Frage: {input}\")\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c649b00b-9fb9-4574-b6d6-5fca64f39ee6",
   "metadata": {},
   "source": [
    "### Retriever\n",
    "\n",
    "Die folgende Klasse `PartyRetriever` sucht für jede Partei `k=3` zur Frage passende Aussagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e7ebe1-a188-4383-a0c2-4e970b2ac6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PartyRetriever(BaseRetriever):\n",
    "    \"\"\"\n",
    "    A retriever that retrieves documents from the party programs\"\"\"\n",
    "\n",
    "    docs: Mapping = dict()\n",
    "    vectorstore: VectorStore\n",
    "    embeddings: Embeddings\n",
    "\n",
    "    def __init__(self, vectorstore, embeddings, docs=docs):\n",
    "        super().__init__(vectorstore=vectorstore, embeddings=embeddings)\n",
    "        self.embeddings = embeddings\n",
    "        self.vectorstore = vectorstore\n",
    "        self.docs = docs\n",
    "   \n",
    "\n",
    "    def _get_relevant_documents(\n",
    "        self,\n",
    "        query: str,\n",
    "        *,\n",
    "        run_manager: CallbackManagerForRetrieverRun,\n",
    "    ) -> List[Document]:\n",
    "        results = []\n",
    "        # Erzeuge Embedding für die Frage\n",
    "        query_embedding = self.embeddings.embed_query(query)\n",
    "\n",
    "        # Suche für jede Partei passende Aussage\n",
    "        for party in self.docs:\n",
    "            results += self.vectorstore.similarity_search_by_vector(\n",
    "                query_embedding, k=3, filter={'party': party})\n",
    "\n",
    "        return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fe7d04-c17e-4d97-a927-301202091888",
   "metadata": {},
   "source": [
    "### RetrievalChain\n",
    "\n",
    "Die folgende *Retrieval Chain* erzeugt mithilfe des Retrievers und des ChatPromptTemplates eine Antwort auf eine Benutzerfrage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13279f7e-aa1f-4362-97ea-c67e59ec60a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = PartyRetriever(vectorstore, OpenAIEmbeddings(model=EMBEDDING_MODEL, api_key=OPENAI_API_KEY), docs)\n",
    "\n",
    "\n",
    "retrieval_chain = create_retrieval_chain(\n",
    "    retriever=retriever,\n",
    "    combine_docs_chain=create_stuff_documents_chain(\n",
    "        llm=LLM,\n",
    "        prompt=PROMPT,\n",
    "        document_prompt=PromptTemplate.from_template(\"{party}: {page_content}\")\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16403560-712f-4717-b70e-f98c6d51212d",
   "metadata": {},
   "source": [
    "Testen Sie die Chain mit eigenen Fragen!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0528b58e-3699-4e09-a327-c8df82a481de",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_chain.invoke({\"input\": \"Was ist die Haltung der Parteien zur Schuldenbremse und zu Investitionen?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edf64b4-905a-484a-b6f6-c2b2d1801277",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
