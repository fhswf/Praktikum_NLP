{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Klassifikation von Texten mithilfe von Transformern\n",
    "\n",
    "*Transformer* sind seit ChatGPT in aller Munde. Mit den \"kleinen Geschwistern\" von GPT kann man sehr gut Texte klassifizieren und andere NLP-Aufgaben l√∂sen.\n",
    "Die folgende Beschreibung wie das funktioniert stammt √ºbrigens zu gro√üen Teilen von ChatGPT, lediglich an einigen Stellen habe ich etwas ge√§ndert (damit Sie auch noch selbst etwas zu tun haben)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ja, ich kann Ihnen helfen. Um Twitter-Nachrichten mit einem Transformer-Modell zu klassifizieren, folgen Sie diesen Schritten:\n",
    "\n",
    "1. Installieren Sie die erforderlichen Bibliotheken:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Importieren Sie die erforderlichen Bibliotheken:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Implementieren Sie eine benutzerdefinierte Dataset-Klasse\n",
    "\n",
    "**Aufgabe 1: Erg√§nzen Sie Code zum Bereinigen der Tweets.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "class GermEvalDataset(Dataset):\n",
    "    def __init__(self, tokenizer, data_path, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = pd.read_csv(data_path, sep='\\t', header=None, names=['text', 'label', 'fine'])\n",
    "        \n",
    "        self.data['text'] = self.data['text'].apply(self.clean_tweet)\n",
    "\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def clean_tweet(self, text):\n",
    "        \"\"\" Preprocess and tokenize a tweet. \"\"\"\n",
    "        \n",
    "        # remove handles, i.e. @username\n",
    "        text = re.sub('\\@\\w+', '', text)\n",
    "    \n",
    "        # remove hashtags, quotes, etc.\n",
    "        text = re.sub('[\\#\"\\']+', '', text)\n",
    "        \n",
    "        # replace hyphens with blanks\n",
    "        text = text.replace('-', ' ')\n",
    "        return text\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = self.data.loc[index, 'text']\n",
    "        label = self.data.loc[index, 'label']\n",
    "        \n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            max_length=self.max_len,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        input_ids = inputs['input_ids'][0]\n",
    "        attention_mask = inputs['attention_mask'][0]\n",
    "        \n",
    "        if label == \"OTHER\":\n",
    "            label_tensor = torch.tensor(0)\n",
    "        elif label == \"OFFENSE\":\n",
    "            label_tensor = torch.tensor(1)\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid label: {label} for {text} at {index}\")\n",
    "            \n",
    "        return {\"input_ids\": input_ids, \"attention_mask\": attention_mask, \"labels\": label_tensor}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Laden Sie das pre-trained Modell und den Tokenizer:\n",
    "\n",
    "**ChatGPT schl√§gt hier das Modell `\"deepset/gbert-large\"` vor ‚Äì eine gute Wahl f√ºr deutschsprachige Tweets.\n",
    "Recherchieren Sie im [Model-Hub von Higging Face](https://huggingface.co/models) ein paar Alternativen und vergleichen Sie die Ergebnisse.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at deepset/gbert-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"deepset/gbert-large\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Erstellen Sie die DataLoader f√ºr Training und Validierung:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAX_LEN = 512\n",
    "BATCH_SIZE = 16\n",
    "train_data_path = \"../data/GermEval-2018/germeval2018.training.txt\"\n",
    "val_data_path = \"../data/GermEval-2018/germeval2018.test.txt\"\n",
    "\n",
    "train_dataset = GermEvalDataset(tokenizer, train_data_path, MAX_LEN)\n",
    "val_dataset = GermEvalDataset(tokenizer, val_data_path, MAX_LEN)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Liebe Corinna, wir w√ºrden dich gerne als Mode...\n",
       "1        Sie haben ja auch Recht. Unser Tweet war etwa...\n",
       "2        fr√∂hlicher gru√ü aus der sch√∂nsten stadt der w...\n",
       "3        Amis h√§tten alles und jeden gew√§hlt...nur Hil...\n",
       "4        kein verl√§√ülicher Verhandlungspartner. Nachka...\n",
       "                              ...                        \n",
       "5004    Gegens. Zul. zu Patenamt &amp; gegenseitige An...\n",
       "5005     Zu Merkel f√§llt mir nur ein, ein Mal Verr√§ter...\n",
       "5006      Ein richtiges Zeichen unserer Nachbarn...sch...\n",
       "5007     ,Honecker‚ÄòMerkel macht uns zur ,DDR‚Äò Klagen w...\n",
       "5008    Warum wurden die G20 Chaoten nicht sofort auf ...\n",
       "Name: text, Length: 5009, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.data.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Erstellen Sie die Trainings-Argumente:\n",
    "\n",
    "**Die Vorgaben von ChatGPT sind in Ordnung, aber schauen Sie einmal, was passiert, wenn Sie an den Parametern `BATCH_SIZE` und `learning_rate` \"drehen\".**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    report_to=None,\n",
    "    learning_rate=1e-5,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    num_train_epochs=5,\n",
    "    logging_steps=100,\n",
    "    save_steps=1000,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    seed=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Definieren Sie die Metrik-Funktion:\n",
    "\n",
    "**Hier habe ich geschummelt und die Metriken aus GermEval 2018 \"nachgebaut\".**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "    preds = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n",
    "    preds = np.argmax(preds, axis=1)\n",
    "    accuracy = (preds == p.label_ids).astype(np.float32).mean().item()\n",
    "    metrics = { \"accuracy\": accuracy }\n",
    "    for val, key in enumerate(['OTHER', 'OFFENSE']):\n",
    "        tp = ((preds == p.label_ids) * (preds == val)).sum().item()\n",
    "        fp = ((preds != p.label_ids) * (preds == val)).sum().item()\n",
    "        fn = ((preds != p.label_ids) * (preds != val)).sum().item()\n",
    "\n",
    "        precision = tp / (tp + fp)\n",
    "        recall = tp / (tp + fn)\n",
    "        f1 = 2 * precision * recall / (precision + recall)\n",
    "        metrics[f\"precision_{key}\"] = precision\n",
    "        metrics[f\"recall_{key}\"] = recall\n",
    "        metrics[f\"f1_{key}\"] = f1\n",
    "        \n",
    "    metrics[f\"precision_AVERAGE\"] = 0.5 * (metrics[f\"precision_OTHER\"] + metrics[f\"precision_OFFENSE\"])\n",
    "    metrics[f\"recall_AVERAGE\"] = 0.5 * (metrics[f\"recall_OTHER\"] + metrics[f\"recall_OFFENSE\"])\n",
    "    metrics[f\"f1_AVERAGE\"] = 0.5 * (metrics[f\"f1_OTHER\"] + metrics[f\"f1_OFFENSE\"])\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Erstellen Sie einen Trainer und trainieren Sie das Modell:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgawron-christian\u001b[0m (\u001b[33mfhswf\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/chgaw002/Praktikum_NLP/Veranstaltung_3/wandb/run-20250329_145403-id6bick0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/fhswf/huggingface/runs/id6bick0' target=\"_blank\">./results</a></strong> to <a href='https://wandb.ai/fhswf/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/fhswf/huggingface' target=\"_blank\">https://wandb.ai/fhswf/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/fhswf/huggingface/runs/id6bick0' target=\"_blank\">https://wandb.ai/fhswf/huggingface/runs/id6bick0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='161' max='1570' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 161/1570 13:39 < 2:01:01, 0.19 it/s, Epoch 0.51/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision Other</th>\n",
       "      <th>Recall Other</th>\n",
       "      <th>F1 Other</th>\n",
       "      <th>Precision Offense</th>\n",
       "      <th>Recall Offense</th>\n",
       "      <th>F1 Offense</th>\n",
       "      <th>Precision Average</th>\n",
       "      <th>Recall Average</th>\n",
       "      <th>F1 Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.503200</td>\n",
       "      <td>0.489590</td>\n",
       "      <td>0.803119</td>\n",
       "      <td>0.788244</td>\n",
       "      <td>0.960409</td>\n",
       "      <td>0.865851</td>\n",
       "      <td>0.864947</td>\n",
       "      <td>0.495652</td>\n",
       "      <td>0.630182</td>\n",
       "      <td>0.826595</td>\n",
       "      <td>0.728031</td>\n",
       "      <td>0.748017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!wandb logout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Optional: Bewerten Sie das Modell nach dem Training:\n",
    "\n",
    "```python\n",
    "trainer.evaluate()\n",
    "```\n",
    "\n",
    "Das trainierte Modell kann jetzt zur Klassifikation von Twitter-Nachrichten verwendet werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
